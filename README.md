# LiWi-HAR

These are the code and data for the paper: [LiWi-HAR: Human Activity Recognition using Lightweight Programmable WiFi Chips].

LiWi-HAR is to propose a new human activity segmentation and recognition scheme based on WiFi Channel State Information (CSI).


# Citation

@ARTICLE{LiWi-HAR2023,  
&nbsp; &nbsp; author={Weixi Liang and Rongshan Tang and Sihan Jaing and Ruqi Wang and Yubin Zhao and Cheng-Zhong Xu and Xudong Long and Zhuolong Chen and Xiaofan Li},  
&nbsp; &nbsp; title={LiWi-HAR: Human Activity Recognition using Lightweight Programmable WiFi Chips},  
&nbsp; &nbsp; year={2023},  
}


# DataSet

The data that we extract from raw CSI data for our experiments can be downloaded from Baidu Netdisk:

Raw CSI data we collected can be downloaded via Baidu. Note that there is need to download the Data_RawCSIDat and Data_Continuous for running our experiments.

All raw CSI data: DATA
Baidu Netdisk：https://pan.baidu.com/s/1bUsv9rPpYuu1xekdwqYczA?(Password：0827)

Data of Raw CSI: Data_RawCSIDat  
Baidu Netdisk: https://pan.baidu.com/s/1ZUkZlyHI-oHvDNWWErVn5Q?(Password: aidu)

Data of Raw Continuous CSI: Data_Continuous  
Baidu: https://pan.baidu.com/s/1NmU649cHy10f9ej6zUAwdQ?(Password:8ts1)


# Requirement
Python3.7  
pytorch 
Matlab R2020b
The codes are tested under window10 and it should be ok for ESP Espressif. 


# Folder descriptions:

*01_preprocess:*
This is used to extract amplitudes from raw CSI *.dat files, and save as *.mat files, aiming at generating files in the folder Data_CsiAmplitude. 

*02_segment:*
This is used to discreize continuous CSI data into bins for segmentation which will be used in the activity segmentation algorithm. 

*03_extraction:*
This is used to extract the features from the CSI data. 

*04_identify:*
This is for training the activities recognition model, and inferring the state labels of CSI data bins generated by Data_CsiFeature.

*05_optimization:*
This is used to optimize the activities recognition model by pre-training the network weights and thresholds.

![Figure](https://github.com/liangwxsysu/LiWi-HAR/blob/master/Visual_Activities_Segementaiotn.jpg)
<p align="center">Figure 1. Visual Inspection about start and end points of activities. </p>


# Motivation for LiWi-HAR
Due to the fluctuation of CSI amplitudes when activities occur are much larger than that when no activity presents, most existing works focus on designing threshold-based segmentation methods, which attempt to seek an optimal threshold to detect the start and end of an activity. If the fluctuation degree of CSI waveforms exceeds this threshold, an activity is considered to happen.

However, exsiting algorithm suffers performance degradation in mixed activities. Because the threshold is a relatively fixed value, which considers the mixed activities as the environmental noise. Thus, the algorithms cannot accurately identify the start and end points of each activity in the sequence of mixed activities. To effectively slice the activity segment of the CSI data, we firstly calculate the data variance in the stationary case, and compare the difference between the CSI data in the moving scenario and the variance of stationary case. Then, the beginning and end of a certain activity from the data flow are determined. This proposed method can adapt the slicing threshold according to the environmental changes and make the system more robust.

In addtion，with the development of the deep learning, there are a large number of systems using deeping learning algorithm to directly complete human activity recognition. Although these algorithm can improve accuracy of recognition, they are not suitable for small data scenarios because they require a large amount of data to train neural networks. And this algorithm is not easy to be embedded in hareware devices because of the complexity. Therefore, we desgin a low comlexity deep learing algorithm to solve the problem of human activity recognition in small data scenes.

![Figure](https://github.com/liangwxsysu/LiWi-HAR/blob/master/Visual_Segmentaion_Threshold.jpg)
<p align="center">Figure 2. Performance of threshold-based activity segmentation methods for mixed activities. </p>

# DeepSeg Overview
LiWi-HAR system consists of the hardware platform which employs the programmable chips and data processing methods implemented on such platform. The main task of LiWi-HAR platform is to collect CSI data. The system collects the CSI data at the receiver side using two development ESP32 boards. The development board has
a built-in ESP32-U4WDH chip, including Xtensa dual-core 32-bit LX6 microprocessor, and supports clock frequencies up to 240 MHz. Such chip contains a low-power MCU module that integrate WiFi and Bluetooth, with various open source functions and interfaces, which is suitable for various IoT application scenarios, e.g., smart home, consumer electronics and industrial control.The ESP32 board provides CSI signal stream with 192 sub-carriers and two CSI streams are collected in the experiment between one transmitter antenna and two receiver antennas. The number of Tx and Rx nodes can be changed according to the application requirements. The data collecting rate is set to 100 pkts/s.

In addition to the platform, the data processing methods are also developed as illustrated in the framework of Fig. 3. The data processing methods include data preprocessing, activities segmentation and recognition. The data preprocessing intends to filter out the noise and aggregates data. Thus, we adopt an outlier detection algorithm based on MAMD for reducing noise. Then we employ PCA for aggregation to reduce the dimension of CSI data blocks. In activity segmentation design, we propose an activity detection algorithm based on the difference in movement variance to detect the start and end time of the CSI data flow for a specific activity, and slice the continuous data stream into several independent segments. For activity recognition, the activity features are extracted by statistical method. Then we design a double hidden layer BPNN based on PSO algorithm to recognize the activities efficiently

![Figure](https://github.com/liangwxsysu/LiWi-HAR/blob/master/LiWiHAR_framework.jpg)
<p align="center">Figure 3. DeepSeg Framework. </p>




